{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "ratings_base = pd.read_csv('ml-100k/ua.base', sep='\\t', names=rs_cols, encoding='latin-1')\n",
    "ratings_test = pd.read_csv('ml-100k/ua.base', sep='\\t', names=rs_cols, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users_base = ratings_base['user_id'].unique().max()\n",
    "n_items_base = ratings_base['movie_id'].unique().max()\n",
    "\n",
    "n_users_base,n_items_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 1682)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users_test = ratings_test['user_id'].unique().max()\n",
    "n_items_test = ratings_test['movie_id'].unique().max()\n",
    "n_users_test,n_items_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = np.zeros((n_users_base, n_items_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_matrix = np.zeros((n_users_test, n_items_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in ratings_base.itertuples():\n",
    "    train_matrix[line[1]-1,line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 3., 4., ..., 0., 0., 0.],\n",
       "       [4., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 5., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=np.array([[1,2,3,],[4,5,6],[7,8,9]])#train matrix\n",
    "arr2=np.array([[0,0,0],[0,0,0],[0,0,0]])#test matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2[0]=arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_users_id_list=[]\n",
    "while True:\n",
    "    rnd=np.random.randint(943)\n",
    "    if len(random_users_id_list) < 94:\n",
    "        if rnd in random_users_id_list:\n",
    "            continue\n",
    "        else:\n",
    "            random_users_id_list.append(rnd)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_users_id_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4,\n",
       " 12,\n",
       " 13,\n",
       " 17,\n",
       " 19,\n",
       " 32,\n",
       " 40,\n",
       " 59,\n",
       " 70,\n",
       " 82,\n",
       " 100,\n",
       " 110,\n",
       " 119,\n",
       " 128,\n",
       " 130,\n",
       " 148,\n",
       " 150,\n",
       " 159,\n",
       " 160,\n",
       " 175,\n",
       " 210,\n",
       " 213,\n",
       " 224,\n",
       " 225,\n",
       " 232,\n",
       " 242,\n",
       " 250,\n",
       " 275,\n",
       " 277,\n",
       " 278,\n",
       " 295,\n",
       " 305,\n",
       " 317,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 332,\n",
       " 355,\n",
       " 369,\n",
       " 386,\n",
       " 395,\n",
       " 400,\n",
       " 420,\n",
       " 431,\n",
       " 438,\n",
       " 460,\n",
       " 462,\n",
       " 481,\n",
       " 491,\n",
       " 492,\n",
       " 507,\n",
       " 511,\n",
       " 519,\n",
       " 549,\n",
       " 550,\n",
       " 556,\n",
       " 559,\n",
       " 563,\n",
       " 584,\n",
       " 598,\n",
       " 604,\n",
       " 616,\n",
       " 630,\n",
       " 643,\n",
       " 652,\n",
       " 658,\n",
       " 690,\n",
       " 721,\n",
       " 722,\n",
       " 725,\n",
       " 745,\n",
       " 750,\n",
       " 755,\n",
       " 757,\n",
       " 784,\n",
       " 795,\n",
       " 801,\n",
       " 806,\n",
       " 815,\n",
       " 816,\n",
       " 823,\n",
       " 852,\n",
       " 863,\n",
       " 872,\n",
       " 877,\n",
       " 880,\n",
       " 883,\n",
       " 890,\n",
       " 912,\n",
       " 913,\n",
       " 917,\n",
       " 919,\n",
       " 933,\n",
       " 935]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_users_id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 94 kullanıcın oy verdikleri ilk itemleri ve ratingleri  bulup tutmak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_first_rating_movie=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "her user verdiği oylardan random seçilecek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in random_users_id_list:\n",
    "    for item in range(n_items_base):\n",
    "        if train_matrix[user][item] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            users_first_rating_movie.append(item)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 12, 13, 17, 19, 32, 40, 59, 70, 82, 100, 110, 119, 128, 130, 148, 150, 159, 160, 175, 210, 213, 224, 225, 232, 242, 250, 275, 277, 278, 295, 305, 317, 325, 326, 327, 332, 355, 369, 386, 395, 400, 420, 431, 438, 460, 462, 481, 491, 492, 507, 511, 519, 549, 550, 556, 559, 563, 584, 598, 604, 616, 630, 643, 652, 658, 690, 721, 722, 725, 745, 750, 755, 757, 784, 795, 801, 806, 815, 816, 823, 852, 863, 872, 877, 880, 883, 890, 912, 913, 917, 919, 933, 935]\n"
     ]
    }
   ],
   "source": [
    "print(random_users_id_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 0, 6, 0, 0, 244, 0, 6, 5, 0, 0, 241, 0, 241, 8, 244, 0, 0, 14, 6, 8, 6, 21, 8, 3, 0, 0, 0, 244, 0, 0, 12, 3, 0, 0, 3, 99, 257, 13, 0, 0, 0, 3, 0, 6, 8, 0, 49, 44, 0, 0, 49, 99, 0, 1, 11, 0, 49, 9, 0, 0, 16, 287, 116, 0, 3, 63, 12, 8, 0, 0, 0, 0, 3, 49, 0, 6, 0, 242, 6, 242, 257, 0, 258, 7, 0, 13, 14, 0, 215, 0, 244, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(users_first_rating_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0, 3.0, 5.0, 5.0, 3.0, 3.0, 4.0, 5.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 5.0, 3.0, 5.0, 4.0, 2.0, 5.0, 3.0, 5.0, 5.0, 5.0, 3.0, 4.0, 4.0, 5.0, 3.0, 3.0, 5.0, 4.0, 2.0, 3.0, 4.0, 3.0, 4.0, 5.0, 3.0, 4.0, 4.0, 2.0, 3.0, 2.0, 4.0, 5.0, 1.0, 4.0, 3.0, 3.0, 5.0, 5.0, 4.0, 3.0, 2.0, 5.0, 4.0, 4.0, 3.0, 4.0, 4.0, 1.0, 3.0, 4.0, 4.0, 3.0, 5.0, 2.0, 3.0, 4.0, 4.0, 3.0, 4.0, 4.0, 5.0, 2.0, 5.0, 4.0, 4.0, 4.0, 1.0, 3.0, 5.0, 1.0, 3.0, 4.0, 4.0, 4.0, 2.0, 3.0, 3.0, 2.0, 2.0, 4.0, "
     ]
    }
   ],
   "source": [
    "for i in range(94):\n",
    "    print(train_matrix[random_users_id_list[i]][users_first_rating_movie[i]], end=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test matrix oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(random_users_id_list)):\n",
    "    test_matrix[random_users_id_list[i]][users_first_rating_movie[i]]=train_matrix[random_users_id_list[i]][users_first_rating_movie[i]]\n",
    "    train_matrix[random_users_id_list[i]][users_first_rating_movie[i]]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 12, 13, 17, 19, 32, 40, 59, 70, 82, 100, 110, 119, 128, 130, 148, 150, 159, 160, 175, 210, 213, 224, 225, 232, 242, 250, 275, 277, 278, 295, 305, 317, 325, 326, 327, 332, 355, 369, 386, 395, 400, 420, 431, 438, 460, 462, 481, 491, 492, 507, 511, 519, 549, 550, 556, 559, 563, 584, 598, 604, 616, 630, 643, 652, 658, 690, 721, 722, 725, 745, 750, 755, 757, 784, 795, 801, 806, 815, 816, 823, 852, 863, 872, 877, 880, 883, 890, 912, 913, 917, 919, 933, 935]\n"
     ]
    }
   ],
   "source": [
    "print(random_users_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0, 3.0, 5.0, 5.0, 3.0, 3.0, 4.0, 5.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 5.0, 3.0, 5.0, 4.0, 2.0, 5.0, 3.0, 5.0, 5.0, 5.0, 3.0, 4.0, 4.0, 5.0, 3.0, 3.0, 5.0, 4.0, 2.0, 3.0, 4.0, 3.0, 4.0, 5.0, 3.0, 4.0, 4.0, 2.0, 3.0, 2.0, 4.0, 5.0, 1.0, 4.0, 3.0, 3.0, 5.0, 5.0, 4.0, 3.0, 2.0, 5.0, 4.0, 4.0, 3.0, 4.0, 4.0, 1.0, 3.0, 4.0, 4.0, 3.0, 5.0, 2.0, 3.0, 4.0, 4.0, 3.0, 4.0, 4.0, 5.0, 2.0, 5.0, 4.0, 4.0, 4.0, 1.0, 3.0, 5.0, 1.0, 3.0, 4.0, 4.0, 4.0, 2.0, 3.0, 3.0, 2.0, 2.0, 4.0, "
     ]
    }
   ],
   "source": [
    "for i in random_users_id_list:\n",
    "    print(np.sum(test_matrix[i]), end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, "
     ]
    }
   ],
   "source": [
    "for i in range(94):\n",
    "    print(train_matrix[random_users_id_list[i]][users_first_rating_movie[i]], end=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test ve train matrix 'i oluşturuldu test+train=base(MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (943, 943)\n",
      "type:  <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.09131022, -0.00581008, ...,  0.00910694,\n",
       "         0.10831478,  0.30758436],\n",
       "       [ 0.09131022,  1.        ,  0.10288466, ...,  0.1627796 ,\n",
       "         0.1442557 ,  0.03401889],\n",
       "       [-0.00581008,  0.10288466,  1.        , ...,  0.01597579,\n",
       "         0.09786267, -0.01432321],\n",
       "       ...,\n",
       "       [ 0.00910694,  0.1627796 ,  0.01597579, ...,  1.        ,\n",
       "         0.0242929 , -0.0044431 ],\n",
       "       [ 0.10831478,  0.1442557 ,  0.09786267, ...,  0.0242929 ,\n",
       "         1.        ,  0.09312477],\n",
       "       [ 0.30758436,  0.03401889, -0.01432321, ..., -0.0044431 ,\n",
       "         0.09312477,  1.        ]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-user_similart\n",
    "user_similarity = pairwise_distances(train_matrix, metric='correlation')\n",
    "user_similarity=1-user_similarity\n",
    "print('shape: ',user_similarity.shape)\n",
    "print('type: ',type(user_similarity))\n",
    "user_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# diogonalları 0'lama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-93-1ceac2c51665>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-93-1ceac2c51665>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    len(user_similarity)correlationjaccard\u001b[0m\n\u001b[1;37m                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "len(user_similarity)correlationjaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(user_similarity)):\n",
    "    for j in range(len(user_similarity)):\n",
    "        if i == j:\n",
    "            user_similarity[i][j]=0\n",
    "        else:\n",
    "            continue\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,"
     ]
    }
   ],
   "source": [
    "for i in range(len(user_similarity)):\n",
    "    print(user_similarity[i][i], end=\" ,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function ndarray.sort>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_similarity.sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=user_similarity.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 91,  63, 513, 434, 822, 737, 863, 267, 456, 915,   0], dtype=int64)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][-11:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_n = user_similarity.argsort()[:,-11:][:,::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 11)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47600819419518414"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_similarity[0][915]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40383770391586093"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_similarity[0][681]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45041621983950075"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_similarity[1][930]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml=[1,2,5,8,9,123,62,1231,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=np.array([[4,5,6],[3,2,1],[7,8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 5, 6],\n",
       "       [3, 2, 1],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [2, 1, 0],\n",
       "       [0, 1, 2]], dtype=int64)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=arr.argsort()[:,1:][:,::-1]# doğru olan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1],\n",
       "       [0, 1],\n",
       "       [2, 1]], dtype=int64)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_user_user(train_matrix, user_similarity, n_similar = 10):\n",
    "    # sort edip ters indexlerini ters çeviriyor seçilen en yakın user sayısına göre\n",
    "    similar_n = user_similarity.argsort()[:,n_similar:][:,::-1]# kontrol et\n",
    "    # pred matrix'i oluşturuluyor\n",
    "    pred = np.zeros((n_users_base,n_items_base))\n",
    "    \n",
    "    for i,users in enumerate(similar_n):# pred yapılıyor\n",
    "        similar_users_indexes = users\n",
    "        similarity_n = user_similarity[i,similar_users_indexes]\n",
    "        matrix_n = train_matrix[similar_users_indexes,:]\n",
    "        rated_items = similarity_n[:,np.newaxis].T.dot(matrix_n - matrix_n.mean(axis=1)[:,np.newaxis])/ similarity_n.sum()\n",
    "        pred[i,:]  = rated_items\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape  (943, 1682)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.33767857e+00,  1.00343630e+00,  6.90377618e-01, ...,\n",
       "         2.53183413e-01,  2.61061179e-01,  2.62545789e-01],\n",
       "       [ 1.41526309e+00,  1.80970731e-01,  2.24765095e-01, ...,\n",
       "        -4.67950259e-02, -4.93227574e-02, -5.11822644e-02],\n",
       "       [ 7.52522093e-01,  9.88781053e-02,  1.32108385e-01, ...,\n",
       "        -4.06503173e-02, -5.11639486e-02, -5.41599406e-02],\n",
       "       ...,\n",
       "       [ 2.05732845e+00,  2.23032870e-01,  2.37106516e-01, ...,\n",
       "        -1.56865964e-01, -1.56376520e-01, -1.55295235e-01],\n",
       "       [ 1.58130384e+00,  4.67931344e-01,  1.88863299e-01, ...,\n",
       "        -8.09173306e-02, -7.77886869e-02, -8.09400621e-02],\n",
       "       [ 2.17792590e+00,  8.89994422e-01,  5.04955081e-01, ...,\n",
       "        -5.80273476e-03,  3.09686880e-03,  2.13484415e-03]])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "predictions = predict_user_user(train_matrix,user_similarity, 10) + train_matrix.mean(axis=1)[:, np.newaxis]# 30 olması daha iyi\n",
    "print('predictions shape ',predictions.shape)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings = predictions[test_matrix.nonzero()]\n",
    "\n",
    "test_truth = test_matrix[test_matrix.nonzero()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.270698330657104"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(predicted_ratings,test_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 5., 5., 3., 3., 4., 5., 3., 4., 3., 4., 4., 4., 5., 3., 5.,\n",
       "       4., 2., 5., 3., 5., 5., 5., 3., 4., 4., 5., 3., 3., 5., 4., 2., 3.,\n",
       "       4., 3., 4., 5., 3., 4., 4., 2., 3., 2., 4., 5., 1., 4., 3., 3., 5.,\n",
       "       5., 4., 3., 2., 5., 4., 4., 3., 4., 4., 1., 3., 4., 4., 3., 5., 2.,\n",
       "       3., 4., 4., 3., 4., 4., 5., 2., 5., 4., 4., 4., 1., 3., 5., 1., 3.,\n",
       "       4., 4., 4., 2., 3., 3., 2., 2., 4.])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4067770544564173"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6721274200259315"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8099696717468028"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_truth[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_truth[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.85063912,  2.63360571,  3.066485  ,  2.25646171,  2.59466506,\n",
       "        0.50684754,  1.20182777,  2.3882842 , -0.12483748,  3.0659562 ,\n",
       "        2.78152761,  1.02567644,  0.38528735,  1.34331083,  2.8484309 ,\n",
       "        2.46390558,  1.80540855,  2.63724722, -0.04356276,  2.29235771,\n",
       "        1.31918191,  1.57493698,  1.2080226 ,  1.1829724 ,  3.05889094,\n",
       "        2.50377998,  2.00574654,  1.66956401,  2.15552882,  2.10063094,\n",
       "        2.86354878,  3.58501237,  2.739144  ,  2.11016871,  2.72097157,\n",
       "        1.15832569,  2.07050605,  3.47656693,  1.42033111,  2.95736734,\n",
       "        1.01088546,  1.67351749,  1.88601515,  1.47599978,  0.66799753,\n",
       "        2.02357752,  0.63110407,  2.33035962,  1.94221257, -0.02681972,\n",
       "        3.6430619 ,  3.31950498,  2.11237969,  1.33640263,  2.38703681,\n",
       "        2.72664119,  2.38052412,  0.20570373,  0.61871144,  0.20813669,\n",
       "        2.92932521,  1.66005864,  1.82696953,  1.42910336,  2.42398138,\n",
       "        2.34766048,  1.24804254,  0.21541119,  2.4439872 ,  1.18878607,\n",
       "        2.93233004,  0.83132675,  0.63250815,  1.31171915,  1.82363498,\n",
       "        3.36473428,  2.97499288,  1.00602086,  1.64151692,  3.17149017,\n",
       "        1.26051151,  2.67506266,  2.37664815,  1.24810996,  1.74014395,\n",
       "        0.6895246 ,  1.56561539,  2.7483029 ,  3.26720337,  1.9301794 ,\n",
       "        0.91615394,  1.31010228,  2.8928618 ,  2.72874179])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "D:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "rs_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "\n",
    "ratings_base = pd.read_csv('ml-1m/ratings.dat', sep='::', names=rs_cols, encoding='latin-1')\n",
    "ratings_test = pd.read_csv('ml-1m/ratings.dat', sep='::', names=rs_cols, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>unix_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  movie_id  rating  unix_timestamp\n",
       "0        1      1193       5       978300760\n",
       "1        1       661       3       978302109\n",
       "2        1       914       3       978301968\n",
       "3        1      3408       4       978300275\n",
       "4        1      2355       5       978824291"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3952)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users_base = ratings_base['user_id'].unique().max()\n",
    "n_items_base = ratings_base['movie_id'].unique().max()\n",
    "\n",
    "n_users_base,n_items_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3952)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users_test = ratings_test['user_id'].unique().max()\n",
    "n_items_test = ratings_test['movie_id'].unique().max()\n",
    "n_users_test,n_items_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_matrix = np.zeros((n_users_base, n_items_base))\n",
    "test_matrix = np.zeros((n_users_test, n_items_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in ratings_base.itertuples():\n",
    "    train_matrix[line[1]-1,line[2]-1] = line[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [3., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6040"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3952"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_items_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_users_id_list=[]\n",
    "while True:\n",
    "    rnd=np.random.randint(6040)\n",
    "    if len(random_users_id_list) < 604:\n",
    "        if rnd in random_users_id_list:\n",
    "            continue\n",
    "        else:\n",
    "            random_users_id_list.append(rnd)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_users_id_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6,\n",
       " 8,\n",
       " 22,\n",
       " 41,\n",
       " 56,\n",
       " 73,\n",
       " 83,\n",
       " 86,\n",
       " 106,\n",
       " 108,\n",
       " 120,\n",
       " 123,\n",
       " 131,\n",
       " 135,\n",
       " 136,\n",
       " 143,\n",
       " 148,\n",
       " 164,\n",
       " 175,\n",
       " 177,\n",
       " 181,\n",
       " 184,\n",
       " 198,\n",
       " 199,\n",
       " 203,\n",
       " 220,\n",
       " 228,\n",
       " 245,\n",
       " 254,\n",
       " 278,\n",
       " 279,\n",
       " 283,\n",
       " 284,\n",
       " 287,\n",
       " 308,\n",
       " 311,\n",
       " 313,\n",
       " 320,\n",
       " 326,\n",
       " 329,\n",
       " 330,\n",
       " 349,\n",
       " 366,\n",
       " 431,\n",
       " 442,\n",
       " 446,\n",
       " 458,\n",
       " 473,\n",
       " 478,\n",
       " 482,\n",
       " 487,\n",
       " 518,\n",
       " 527,\n",
       " 533,\n",
       " 547,\n",
       " 560,\n",
       " 563,\n",
       " 564,\n",
       " 567,\n",
       " 570,\n",
       " 582,\n",
       " 623,\n",
       " 624,\n",
       " 635,\n",
       " 650,\n",
       " 656,\n",
       " 693,\n",
       " 709,\n",
       " 726,\n",
       " 729,\n",
       " 730,\n",
       " 752,\n",
       " 756,\n",
       " 757,\n",
       " 766,\n",
       " 771,\n",
       " 789,\n",
       " 805,\n",
       " 830,\n",
       " 842,\n",
       " 869,\n",
       " 875,\n",
       " 883,\n",
       " 898,\n",
       " 910,\n",
       " 921,\n",
       " 926,\n",
       " 930,\n",
       " 947,\n",
       " 959,\n",
       " 961,\n",
       " 976,\n",
       " 977,\n",
       " 991,\n",
       " 1002,\n",
       " 1006,\n",
       " 1015,\n",
       " 1018,\n",
       " 1025,\n",
       " 1051,\n",
       " 1053,\n",
       " 1068,\n",
       " 1074,\n",
       " 1095,\n",
       " 1115,\n",
       " 1116,\n",
       " 1123,\n",
       " 1127,\n",
       " 1153,\n",
       " 1172,\n",
       " 1177,\n",
       " 1179,\n",
       " 1180,\n",
       " 1182,\n",
       " 1183,\n",
       " 1186,\n",
       " 1189,\n",
       " 1194,\n",
       " 1203,\n",
       " 1206,\n",
       " 1207,\n",
       " 1218,\n",
       " 1219,\n",
       " 1229,\n",
       " 1235,\n",
       " 1236,\n",
       " 1247,\n",
       " 1248,\n",
       " 1249,\n",
       " 1253,\n",
       " 1262,\n",
       " 1264,\n",
       " 1265,\n",
       " 1268,\n",
       " 1281,\n",
       " 1282,\n",
       " 1293,\n",
       " 1329,\n",
       " 1330,\n",
       " 1334,\n",
       " 1347,\n",
       " 1359,\n",
       " 1370,\n",
       " 1373,\n",
       " 1395,\n",
       " 1400,\n",
       " 1405,\n",
       " 1408,\n",
       " 1411,\n",
       " 1419,\n",
       " 1420,\n",
       " 1421,\n",
       " 1433,\n",
       " 1435,\n",
       " 1461,\n",
       " 1478,\n",
       " 1483,\n",
       " 1501,\n",
       " 1503,\n",
       " 1528,\n",
       " 1531,\n",
       " 1535,\n",
       " 1536,\n",
       " 1570,\n",
       " 1618,\n",
       " 1652,\n",
       " 1657,\n",
       " 1658,\n",
       " 1691,\n",
       " 1694,\n",
       " 1700,\n",
       " 1701,\n",
       " 1706,\n",
       " 1710,\n",
       " 1718,\n",
       " 1736,\n",
       " 1743,\n",
       " 1750,\n",
       " 1751,\n",
       " 1753,\n",
       " 1778,\n",
       " 1781,\n",
       " 1782,\n",
       " 1785,\n",
       " 1797,\n",
       " 1804,\n",
       " 1822,\n",
       " 1826,\n",
       " 1833,\n",
       " 1837,\n",
       " 1849,\n",
       " 1851,\n",
       " 1881,\n",
       " 1884,\n",
       " 1892,\n",
       " 1906,\n",
       " 1907,\n",
       " 1922,\n",
       " 1933,\n",
       " 1942,\n",
       " 1964,\n",
       " 1990,\n",
       " 2011,\n",
       " 2020,\n",
       " 2022,\n",
       " 2023,\n",
       " 2043,\n",
       " 2046,\n",
       " 2055,\n",
       " 2057,\n",
       " 2064,\n",
       " 2070,\n",
       " 2107,\n",
       " 2110,\n",
       " 2127,\n",
       " 2134,\n",
       " 2138,\n",
       " 2142,\n",
       " 2169,\n",
       " 2183,\n",
       " 2195,\n",
       " 2198,\n",
       " 2208,\n",
       " 2216,\n",
       " 2242,\n",
       " 2254,\n",
       " 2264,\n",
       " 2287,\n",
       " 2290,\n",
       " 2327,\n",
       " 2340,\n",
       " 2352,\n",
       " 2359,\n",
       " 2389,\n",
       " 2394,\n",
       " 2423,\n",
       " 2440,\n",
       " 2474,\n",
       " 2480,\n",
       " 2486,\n",
       " 2492,\n",
       " 2494,\n",
       " 2502,\n",
       " 2512,\n",
       " 2555,\n",
       " 2566,\n",
       " 2568,\n",
       " 2584,\n",
       " 2622,\n",
       " 2629,\n",
       " 2636,\n",
       " 2637,\n",
       " 2648,\n",
       " 2652,\n",
       " 2676,\n",
       " 2687,\n",
       " 2697,\n",
       " 2698,\n",
       " 2699,\n",
       " 2711,\n",
       " 2720,\n",
       " 2727,\n",
       " 2738,\n",
       " 2741,\n",
       " 2750,\n",
       " 2755,\n",
       " 2763,\n",
       " 2769,\n",
       " 2778,\n",
       " 2779,\n",
       " 2783,\n",
       " 2817,\n",
       " 2823,\n",
       " 2830,\n",
       " 2833,\n",
       " 2837,\n",
       " 2858,\n",
       " 2859,\n",
       " 2869,\n",
       " 2877,\n",
       " 2879,\n",
       " 2884,\n",
       " 2885,\n",
       " 2893,\n",
       " 2913,\n",
       " 2929,\n",
       " 2938,\n",
       " 2940,\n",
       " 2956,\n",
       " 2963,\n",
       " 2980,\n",
       " 2984,\n",
       " 2999,\n",
       " 3005,\n",
       " 3018,\n",
       " 3027,\n",
       " 3046,\n",
       " 3062,\n",
       " 3084,\n",
       " 3115,\n",
       " 3126,\n",
       " 3139,\n",
       " 3152,\n",
       " 3174,\n",
       " 3178,\n",
       " 3181,\n",
       " 3187,\n",
       " 3189,\n",
       " 3202,\n",
       " 3209,\n",
       " 3220,\n",
       " 3240,\n",
       " 3254,\n",
       " 3260,\n",
       " 3264,\n",
       " 3291,\n",
       " 3293,\n",
       " 3333,\n",
       " 3334,\n",
       " 3339,\n",
       " 3366,\n",
       " 3370,\n",
       " 3386,\n",
       " 3388,\n",
       " 3391,\n",
       " 3435,\n",
       " 3437,\n",
       " 3460,\n",
       " 3479,\n",
       " 3489,\n",
       " 3492,\n",
       " 3500,\n",
       " 3504,\n",
       " 3525,\n",
       " 3543,\n",
       " 3545,\n",
       " 3558,\n",
       " 3574,\n",
       " 3578,\n",
       " 3585,\n",
       " 3591,\n",
       " 3594,\n",
       " 3596,\n",
       " 3600,\n",
       " 3603,\n",
       " 3616,\n",
       " 3618,\n",
       " 3622,\n",
       " 3626,\n",
       " 3630,\n",
       " 3631,\n",
       " 3634,\n",
       " 3636,\n",
       " 3642,\n",
       " 3661,\n",
       " 3662,\n",
       " 3665,\n",
       " 3672,\n",
       " 3676,\n",
       " 3696,\n",
       " 3699,\n",
       " 3701,\n",
       " 3705,\n",
       " 3708,\n",
       " 3716,\n",
       " 3730,\n",
       " 3738,\n",
       " 3764,\n",
       " 3775,\n",
       " 3777,\n",
       " 3797,\n",
       " 3798,\n",
       " 3809,\n",
       " 3810,\n",
       " 3813,\n",
       " 3829,\n",
       " 3836,\n",
       " 3841,\n",
       " 3850,\n",
       " 3857,\n",
       " 3869,\n",
       " 3893,\n",
       " 3898,\n",
       " 3924,\n",
       " 3926,\n",
       " 3931,\n",
       " 3933,\n",
       " 3940,\n",
       " 3945,\n",
       " 3947,\n",
       " 3990,\n",
       " 3996,\n",
       " 4005,\n",
       " 4011,\n",
       " 4036,\n",
       " 4038,\n",
       " 4049,\n",
       " 4053,\n",
       " 4054,\n",
       " 4059,\n",
       " 4086,\n",
       " 4089,\n",
       " 4122,\n",
       " 4128,\n",
       " 4138,\n",
       " 4156,\n",
       " 4176,\n",
       " 4177,\n",
       " 4187,\n",
       " 4194,\n",
       " 4196,\n",
       " 4215,\n",
       " 4226,\n",
       " 4235,\n",
       " 4236,\n",
       " 4260,\n",
       " 4268,\n",
       " 4290,\n",
       " 4298,\n",
       " 4299,\n",
       " 4306,\n",
       " 4320,\n",
       " 4327,\n",
       " 4352,\n",
       " 4355,\n",
       " 4371,\n",
       " 4383,\n",
       " 4384,\n",
       " 4412,\n",
       " 4417,\n",
       " 4419,\n",
       " 4453,\n",
       " 4491,\n",
       " 4496,\n",
       " 4499,\n",
       " 4511,\n",
       " 4514,\n",
       " 4548,\n",
       " 4549,\n",
       " 4552,\n",
       " 4553,\n",
       " 4560,\n",
       " 4581,\n",
       " 4592,\n",
       " 4593,\n",
       " 4602,\n",
       " 4617,\n",
       " 4627,\n",
       " 4630,\n",
       " 4639,\n",
       " 4646,\n",
       " 4648,\n",
       " 4663,\n",
       " 4675,\n",
       " 4683,\n",
       " 4697,\n",
       " 4700,\n",
       " 4702,\n",
       " 4706,\n",
       " 4709,\n",
       " 4749,\n",
       " 4753,\n",
       " 4754,\n",
       " 4786,\n",
       " 4789,\n",
       " 4791,\n",
       " 4793,\n",
       " 4800,\n",
       " 4828,\n",
       " 4831,\n",
       " 4839,\n",
       " 4843,\n",
       " 4853,\n",
       " 4854,\n",
       " 4875,\n",
       " 4902,\n",
       " 4903,\n",
       " 4911,\n",
       " 4912,\n",
       " 4914,\n",
       " 4929,\n",
       " 4950,\n",
       " 4957,\n",
       " 4959,\n",
       " 4968,\n",
       " 4988,\n",
       " 4989,\n",
       " 4992,\n",
       " 4995,\n",
       " 4997,\n",
       " 5008,\n",
       " 5009,\n",
       " 5011,\n",
       " 5021,\n",
       " 5050,\n",
       " 5054,\n",
       " 5059,\n",
       " 5066,\n",
       " 5080,\n",
       " 5082,\n",
       " 5083,\n",
       " 5089,\n",
       " 5096,\n",
       " 5109,\n",
       " 5117,\n",
       " 5134,\n",
       " 5138,\n",
       " 5146,\n",
       " 5150,\n",
       " 5156,\n",
       " 5168,\n",
       " 5174,\n",
       " 5196,\n",
       " 5210,\n",
       " 5218,\n",
       " 5231,\n",
       " 5233,\n",
       " 5242,\n",
       " 5252,\n",
       " 5255,\n",
       " 5259,\n",
       " 5267,\n",
       " 5280,\n",
       " 5281,\n",
       " 5290,\n",
       " 5296,\n",
       " 5300,\n",
       " 5307,\n",
       " 5319,\n",
       " 5322,\n",
       " 5336,\n",
       " 5344,\n",
       " 5365,\n",
       " 5382,\n",
       " 5399,\n",
       " 5402,\n",
       " 5414,\n",
       " 5416,\n",
       " 5425,\n",
       " 5426,\n",
       " 5429,\n",
       " 5433,\n",
       " 5446,\n",
       " 5449,\n",
       " 5454,\n",
       " 5459,\n",
       " 5471,\n",
       " 5475,\n",
       " 5478,\n",
       " 5482,\n",
       " 5484,\n",
       " 5503,\n",
       " 5512,\n",
       " 5516,\n",
       " 5518,\n",
       " 5525,\n",
       " 5526,\n",
       " 5530,\n",
       " 5545,\n",
       " 5551,\n",
       " 5553,\n",
       " 5554,\n",
       " 5572,\n",
       " 5577,\n",
       " 5581,\n",
       " 5607,\n",
       " 5609,\n",
       " 5621,\n",
       " 5641,\n",
       " 5656,\n",
       " 5664,\n",
       " 5668,\n",
       " 5707,\n",
       " 5731,\n",
       " 5732,\n",
       " 5736,\n",
       " 5750,\n",
       " 5758,\n",
       " 5764,\n",
       " 5769,\n",
       " 5779,\n",
       " 5785,\n",
       " 5789,\n",
       " 5799,\n",
       " 5814,\n",
       " 5821,\n",
       " 5845,\n",
       " 5852,\n",
       " 5877,\n",
       " 5920,\n",
       " 5928,\n",
       " 5932,\n",
       " 5935,\n",
       " 5940,\n",
       " 5944,\n",
       " 5946,\n",
       " 5949,\n",
       " 5958,\n",
       " 5965,\n",
       " 5974,\n",
       " 6000,\n",
       " 6006,\n",
       " 6022,\n",
       " 6030]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_users_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_first_rating_movie=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in random_users_id_list:\n",
    "    for item in range(n_items_base):\n",
    "        if train_matrix[user][item] == 0:\n",
    "            continue\n",
    "        else:\n",
    "            users_first_rating_movie.append(item)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 8, 22, 41, 56, 73, 83, 86, 106, 108, 120, 123, 131, 135, 136, 143, 148, 164, 175, 177, 181, 184, 198, 199, 203, 220, 228, 245, 254, 278, 279, 283, 284, 287, 308, 311, 313, 320, 326, 329, 330, 349, 366, 431, 442, 446, 458, 473, 478, 482, 487, 518, 527, 533, 547, 560, 563, 564, 567, 570, 582, 623, 624, 635, 650, 656, 693, 709, 726, 729, 730, 752, 756, 757, 766, 771, 789, 805, 830, 842, 869, 875, 883, 898, 910, 921, 926, 930, 947, 959, 961, 976, 977, 991, 1002, 1006, 1015, 1018, 1025, 1051, 1053, 1068, 1074, 1095, 1115, 1116, 1123, 1127, 1153, 1172, 1177, 1179, 1180, 1182, 1183, 1186, 1189, 1194, 1203, 1206, 1207, 1218, 1219, 1229, 1235, 1236, 1247, 1248, 1249, 1253, 1262, 1264, 1265, 1268, 1281, 1282, 1293, 1329, 1330, 1334, 1347, 1359, 1370, 1373, 1395, 1400, 1405, 1408, 1411, 1419, 1420, 1421, 1433, 1435, 1461, 1478, 1483, 1501, 1503, 1528, 1531, 1535, 1536, 1570, 1618, 1652, 1657, 1658, 1691, 1694, 1700, 1701, 1706, 1710, 1718, 1736, 1743, 1750, 1751, 1753, 1778, 1781, 1782, 1785, 1797, 1804, 1822, 1826, 1833, 1837, 1849, 1851, 1881, 1884, 1892, 1906, 1907, 1922, 1933, 1942, 1964, 1990, 2011, 2020, 2022, 2023, 2043, 2046, 2055, 2057, 2064, 2070, 2107, 2110, 2127, 2134, 2138, 2142, 2169, 2183, 2195, 2198, 2208, 2216, 2242, 2254, 2264, 2287, 2290, 2327, 2340, 2352, 2359, 2389, 2394, 2423, 2440, 2474, 2480, 2486, 2492, 2494, 2502, 2512, 2555, 2566, 2568, 2584, 2622, 2629, 2636, 2637, 2648, 2652, 2676, 2687, 2697, 2698, 2699, 2711, 2720, 2727, 2738, 2741, 2750, 2755, 2763, 2769, 2778, 2779, 2783, 2817, 2823, 2830, 2833, 2837, 2858, 2859, 2869, 2877, 2879, 2884, 2885, 2893, 2913, 2929, 2938, 2940, 2956, 2963, 2980, 2984, 2999, 3005, 3018, 3027, 3046, 3062, 3084, 3115, 3126, 3139, 3152, 3174, 3178, 3181, 3187, 3189, 3202, 3209, 3220, 3240, 3254, 3260, 3264, 3291, 3293, 3333, 3334, 3339, 3366, 3370, 3386, 3388, 3391, 3435, 3437, 3460, 3479, 3489, 3492, 3500, 3504, 3525, 3543, 3545, 3558, 3574, 3578, 3585, 3591, 3594, 3596, 3600, 3603, 3616, 3618, 3622, 3626, 3630, 3631, 3634, 3636, 3642, 3661, 3662, 3665, 3672, 3676, 3696, 3699, 3701, 3705, 3708, 3716, 3730, 3738, 3764, 3775, 3777, 3797, 3798, 3809, 3810, 3813, 3829, 3836, 3841, 3850, 3857, 3869, 3893, 3898, 3924, 3926, 3931, 3933, 3940, 3945, 3947, 3990, 3996, 4005, 4011, 4036, 4038, 4049, 4053, 4054, 4059, 4086, 4089, 4122, 4128, 4138, 4156, 4176, 4177, 4187, 4194, 4196, 4215, 4226, 4235, 4236, 4260, 4268, 4290, 4298, 4299, 4306, 4320, 4327, 4352, 4355, 4371, 4383, 4384, 4412, 4417, 4419, 4453, 4491, 4496, 4499, 4511, 4514, 4548, 4549, 4552, 4553, 4560, 4581, 4592, 4593, 4602, 4617, 4627, 4630, 4639, 4646, 4648, 4663, 4675, 4683, 4697, 4700, 4702, 4706, 4709, 4749, 4753, 4754, 4786, 4789, 4791, 4793, 4800, 4828, 4831, 4839, 4843, 4853, 4854, 4875, 4902, 4903, 4911, 4912, 4914, 4929, 4950, 4957, 4959, 4968, 4988, 4989, 4992, 4995, 4997, 5008, 5009, 5011, 5021, 5050, 5054, 5059, 5066, 5080, 5082, 5083, 5089, 5096, 5109, 5117, 5134, 5138, 5146, 5150, 5156, 5168, 5174, 5196, 5210, 5218, 5231, 5233, 5242, 5252, 5255, 5259, 5267, 5280, 5281, 5290, 5296, 5300, 5307, 5319, 5322, 5336, 5344, 5365, 5382, 5399, 5402, 5414, 5416, 5425, 5426, 5429, 5433, 5446, 5449, 5454, 5459, 5471, 5475, 5478, 5482, 5484, 5503, 5512, 5516, 5518, 5525, 5526, 5530, 5545, 5551, 5553, 5554, 5572, 5577, 5581, 5607, 5609, 5621, 5641, 5656, 5664, 5668, 5707, 5731, 5732, 5736, 5750, 5758, 5764, 5769, 5779, 5785, 5789, 5799, 5814, 5821, 5845, 5852, 5877, 5920, 5928, 5932, 5935, 5940, 5944, 5946, 5949, 5958, 5965, 5974, 6000, 6006, 6022, 6030]\n"
     ]
    }
   ],
   "source": [
    "print(random_users_id_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 0, 0, 5, 46, 33, 109, 20, 110, 0, 0, 33, 0, 0, 2, 355, 0, 49, 1078, 10, 0, 8, 2, 7, 0, 110, 1, 0, 0, 109, 33, 0, 21, 20, 33, 16, 0, 0, 35, 259, 5, 0, 110, 2, 5, 526, 313, 0, 0, 110, 38, 0, 0, 10, 69, 31, 149, 174, 109, 1, 0, 0, 16, 109, 15, 42, 110, 0, 6, 5, 0, 0, 0, 31, 10, 23, 259, 109, 46, 0, 18, 5, 31, 0, 1, 5, 2, 0, 0, 5, 46, 0, 46, 10, 28, 1090, 2, 4, 109, 16, 0, 10, 161, 0, 0, 0, 0, 13, 191, 3, 295, 259, 0, 0, 0, 38, 111, 23, 23, 0, 267, 9, 0, 0, 440, 18, 0, 276, 480, 24, 0, 0, 0, 313, 33, 0, 0, 1, 16, 0, 0, 33, 1, 16, 33, 33, 33, 28, 152, 5, 0, 0, 0, 42, 2, 24, 0, 0, 5, 1, 0, 316, 94, 5, 528, 222, 0, 2, 33, 0, 5, 23, 16, 2, 222, 0, 10, 109, 0, 109, 0, 200, 44, 109, 109, 0, 0, 46, 0, 24, 0, 31, 0, 0, 4, 18, 0, 69, 222, 0, 149, 0, 0, 5, 0, 6, 10, 0, 2, 2, 0, 0, 0, 3, 109, 0, 10, 5, 104, 222, 299, 222, 104, 2, 150, 0, 1, 0, 59, 2, 33, 16, 588, 10, 0, 0, 112, 252, 110, 259, 31, 10, 23, 38, 57, 0, 109, 0, 2, 23, 298, 0, 6, 222, 109, 0, 0, 0, 5, 5, 38, 6, 967, 0, 2, 0, 0, 69, 0, 222, 16, 0, 0, 0, 16, 33, 0, 5, 20, 0, 0, 0, 5, 9, 35, 35, 0, 0, 24, 110, 31, 0, 8, 0, 292, 0, 5, 10, 5, 23, 16, 1, 62, 16, 222, 0, 341, 0, 46, 28, 9, 252, 6, 0, 0, 0, 5, 5, 38, 23, 1, 0, 0, 0, 49, 23, 0, 109, 38, 0, 20, 0, 20, 0, 109, 5, 0, 109, 0, 6, 0, 259, 0, 0, 33, 0, 24, 109, 252, 109, 222, 16, 23, 9, 71, 20, 109, 11, 15, 1, 10, 0, 0, 0, 0, 28, 317, 10, 207, 0, 49, 0, 109, 31, 144, 27, 20, 0, 23, 16, 192, 49, 42, 28, 4, 259, 0, 31, 0, 0, 222, 0, 1, 259, 0, 20, 0, 4, 0, 0, 23, 0, 1, 2, 5, 109, 0, 6, 59, 245, 0, 157, 1, 23, 0, 0, 0, 88, 0, 0, 109, 20, 10, 5, 0, 110, 0, 317, 912, 10, 259, 5, 75, 1, 1192, 0, 259, 355, 492, 0, 33, 0, 3, 3, 109, 110, 28, 526, 0, 0, 0, 29, 110, 245, 24, 248, 0, 230, 33, 40, 0, 0, 592, 362, 0, 10, 0, 15, 10, 49, 0, 33, 33, 0, 0, 49, 0, 919, 35, 0, 47, 0, 0, 33, 593, 0, 0, 4, 5, 0, 0, 40, 382, 259, 258, 479, 245, 61, 0, 0, 0, 0, 264, 259, 0, 0, 10, 49, 1, 31, 24, 109, 192, 259, 9, 0, 10, 0, 0, 0, 33, 0, 85, 0, 0, 376, 0, 328, 0, 0, 9, 0, 0, 4, 169, 0, 0, 94, 4, 0, 2, 10, 10, 9, 0, 24, 9, 57, 0, 0, 0, 0, 33, 110, 0, 5, 24, 5, 151, 4, 31, 0, 16, 0, 82, 109, 0, 20, 12, 0, 31, 20, 31, 27, 15, 15, 0, 0, 9, 15, 0, 10, 0, 967, 28, 252, 49, 4, 6, 0, 69, 23, 33, 46, 100, 28, 10, 0, 16, 24, 1, 10, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "print(users_first_rating_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0, 5.0, 4.0, 4.0, 4.0, 2.0, 5.0, 1.0, 3.0, 4.0, 5.0, 5.0, 5.0, 2.0, 5.0, 3.0, 3.0, 5.0, 4.0, 5.0, 5.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 5.0, 4.0, 4.0, 1.0, 5.0, 5.0, 3.0, 4.0, 3.0, 4.0, 2.0, 4.0, 5.0, 4.0, 5.0, 4.0, 2.0, 4.0, 5.0, 4.0, 5.0, 5.0, 3.0, 3.0, 4.0, 5.0, 5.0, 3.0, 5.0, 5.0, 4.0, 5.0, 4.0, 5.0, 3.0, 5.0, 4.0, 4.0, 4.0, 3.0, 5.0, 3.0, 5.0, 5.0, 5.0, 3.0, 4.0, 4.0, 2.0, 5.0, 3.0, 5.0, 4.0, 3.0, 4.0, 5.0, 4.0, 4.0, 4.0, 3.0, 4.0, 3.0, 5.0, 4.0, 3.0, 5.0, 4.0, "
     ]
    }
   ],
   "source": [
    "for i in range(94):\n",
    "    print(train_matrix[random_users_id_list[i]][users_first_rating_movie[i]], end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(random_users_id_list)):\n",
    "    test_matrix[random_users_id_list[i]][users_first_rating_movie[i]]=train_matrix[random_users_id_list[i]][users_first_rating_movie[i]]\n",
    "    train_matrix[random_users_id_list[i]][users_first_rating_movie[i]]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 8, 22, 41, 56, 73, 83, 86, 106, 108, 120, 123, 131, 135, 136, 143, 148, 164, 175, 177, 181, 184, 198, 199, 203, 220, 228, 245, 254, 278, 279, 283, 284, 287, 308, 311, 313, 320, 326, 329, 330, 349, 366, 431, 442, 446, 458, 473, 478, 482, 487, 518, 527, 533, 547, 560, 563, 564, 567, 570, 582, 623, 624, 635, 650, 656, 693, 709, 726, 729, 730, 752, 756, 757, 766, 771, 789, 805, 830, 842, 869, 875, 883, 898, 910, 921, 926, 930, 947, 959, 961, 976, 977, 991, 1002, 1006, 1015, 1018, 1025, 1051, 1053, 1068, 1074, 1095, 1115, 1116, 1123, 1127, 1153, 1172, 1177, 1179, 1180, 1182, 1183, 1186, 1189, 1194, 1203, 1206, 1207, 1218, 1219, 1229, 1235, 1236, 1247, 1248, 1249, 1253, 1262, 1264, 1265, 1268, 1281, 1282, 1293, 1329, 1330, 1334, 1347, 1359, 1370, 1373, 1395, 1400, 1405, 1408, 1411, 1419, 1420, 1421, 1433, 1435, 1461, 1478, 1483, 1501, 1503, 1528, 1531, 1535, 1536, 1570, 1618, 1652, 1657, 1658, 1691, 1694, 1700, 1701, 1706, 1710, 1718, 1736, 1743, 1750, 1751, 1753, 1778, 1781, 1782, 1785, 1797, 1804, 1822, 1826, 1833, 1837, 1849, 1851, 1881, 1884, 1892, 1906, 1907, 1922, 1933, 1942, 1964, 1990, 2011, 2020, 2022, 2023, 2043, 2046, 2055, 2057, 2064, 2070, 2107, 2110, 2127, 2134, 2138, 2142, 2169, 2183, 2195, 2198, 2208, 2216, 2242, 2254, 2264, 2287, 2290, 2327, 2340, 2352, 2359, 2389, 2394, 2423, 2440, 2474, 2480, 2486, 2492, 2494, 2502, 2512, 2555, 2566, 2568, 2584, 2622, 2629, 2636, 2637, 2648, 2652, 2676, 2687, 2697, 2698, 2699, 2711, 2720, 2727, 2738, 2741, 2750, 2755, 2763, 2769, 2778, 2779, 2783, 2817, 2823, 2830, 2833, 2837, 2858, 2859, 2869, 2877, 2879, 2884, 2885, 2893, 2913, 2929, 2938, 2940, 2956, 2963, 2980, 2984, 2999, 3005, 3018, 3027, 3046, 3062, 3084, 3115, 3126, 3139, 3152, 3174, 3178, 3181, 3187, 3189, 3202, 3209, 3220, 3240, 3254, 3260, 3264, 3291, 3293, 3333, 3334, 3339, 3366, 3370, 3386, 3388, 3391, 3435, 3437, 3460, 3479, 3489, 3492, 3500, 3504, 3525, 3543, 3545, 3558, 3574, 3578, 3585, 3591, 3594, 3596, 3600, 3603, 3616, 3618, 3622, 3626, 3630, 3631, 3634, 3636, 3642, 3661, 3662, 3665, 3672, 3676, 3696, 3699, 3701, 3705, 3708, 3716, 3730, 3738, 3764, 3775, 3777, 3797, 3798, 3809, 3810, 3813, 3829, 3836, 3841, 3850, 3857, 3869, 3893, 3898, 3924, 3926, 3931, 3933, 3940, 3945, 3947, 3990, 3996, 4005, 4011, 4036, 4038, 4049, 4053, 4054, 4059, 4086, 4089, 4122, 4128, 4138, 4156, 4176, 4177, 4187, 4194, 4196, 4215, 4226, 4235, 4236, 4260, 4268, 4290, 4298, 4299, 4306, 4320, 4327, 4352, 4355, 4371, 4383, 4384, 4412, 4417, 4419, 4453, 4491, 4496, 4499, 4511, 4514, 4548, 4549, 4552, 4553, 4560, 4581, 4592, 4593, 4602, 4617, 4627, 4630, 4639, 4646, 4648, 4663, 4675, 4683, 4697, 4700, 4702, 4706, 4709, 4749, 4753, 4754, 4786, 4789, 4791, 4793, 4800, 4828, 4831, 4839, 4843, 4853, 4854, 4875, 4902, 4903, 4911, 4912, 4914, 4929, 4950, 4957, 4959, 4968, 4988, 4989, 4992, 4995, 4997, 5008, 5009, 5011, 5021, 5050, 5054, 5059, 5066, 5080, 5082, 5083, 5089, 5096, 5109, 5117, 5134, 5138, 5146, 5150, 5156, 5168, 5174, 5196, 5210, 5218, 5231, 5233, 5242, 5252, 5255, 5259, 5267, 5280, 5281, 5290, 5296, 5300, 5307, 5319, 5322, 5336, 5344, 5365, 5382, 5399, 5402, 5414, 5416, 5425, 5426, 5429, 5433, 5446, 5449, 5454, 5459, 5471, 5475, 5478, 5482, 5484, 5503, 5512, 5516, 5518, 5525, 5526, 5530, 5545, 5551, 5553, 5554, 5572, 5577, 5581, 5607, 5609, 5621, 5641, 5656, 5664, 5668, 5707, 5731, 5732, 5736, 5750, 5758, 5764, 5769, 5779, 5785, 5789, 5799, 5814, 5821, 5845, 5852, 5877, 5920, 5928, 5932, 5935, 5940, 5944, 5946, 5949, 5958, 5965, 5974, 6000, 6006, 6022, 6030]\n"
     ]
    }
   ],
   "source": [
    "print(random_users_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0, 5.0, 4.0, 4.0, 4.0, 2.0, 5.0, 1.0, 3.0, 4.0, 5.0, 5.0, 5.0, 2.0, 5.0, 3.0, 3.0, 5.0, 4.0, 5.0, 5.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 5.0, 4.0, 4.0, 1.0, 5.0, 5.0, 3.0, 4.0, 3.0, 4.0, 2.0, 4.0, 5.0, 4.0, 5.0, 4.0, 2.0, 4.0, 5.0, 4.0, 5.0, 5.0, 3.0, 3.0, 4.0, 5.0, 5.0, 3.0, 5.0, 5.0, 4.0, 5.0, 4.0, 5.0, 3.0, 5.0, 4.0, 4.0, 4.0, 3.0, 5.0, 3.0, 5.0, 5.0, 5.0, 3.0, 4.0, 4.0, 2.0, 5.0, 3.0, 5.0, 4.0, 3.0, 4.0, 5.0, 4.0, 4.0, 4.0, 3.0, 4.0, 3.0, 5.0, 4.0, 3.0, 5.0, 4.0, 3.0, 4.0, 2.0, 2.0, 3.0, 5.0, 5.0, 3.0, 4.0, 4.0, 4.0, 5.0, 5.0, 4.0, 2.0, 3.0, 5.0, 5.0, 3.0, 5.0, 4.0, 4.0, 4.0, 3.0, 3.0, 4.0, 4.0, 2.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0, 4.0, 4.0, 4.0, 4.0, 5.0, 3.0, 5.0, 5.0, 5.0, 2.0, 4.0, 4.0, 3.0, 4.0, 5.0, 4.0, 5.0, 4.0, 4.0, 4.0, 1.0, 4.0, 5.0, 4.0, 2.0, 4.0, 2.0, 5.0, 4.0, 4.0, 4.0, 3.0, 5.0, 4.0, 3.0, 4.0, 4.0, 4.0, 4.0, 3.0, 4.0, 5.0, 5.0, 5.0, 5.0, 2.0, 2.0, 5.0, 4.0, 5.0, 5.0, 2.0, 3.0, 4.0, 3.0, 4.0, 3.0, 5.0, 5.0, 4.0, 5.0, 3.0, 5.0, 4.0, 4.0, 5.0, 2.0, 4.0, 4.0, 3.0, 5.0, 4.0, 3.0, 4.0, 4.0, 4.0, 5.0, 2.0, 4.0, 4.0, 1.0, 3.0, 4.0, 4.0, 5.0, 3.0, 4.0, 5.0, 5.0, 4.0, 5.0, 4.0, 4.0, 4.0, 4.0, 2.0, 4.0, 5.0, 3.0, 3.0, 4.0, 4.0, 4.0, 3.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 1.0, 4.0, 2.0, 5.0, 1.0, 4.0, 5.0, 4.0, 4.0, 3.0, 5.0, 2.0, 4.0, 5.0, 3.0, 3.0, 3.0, 4.0, 4.0, 5.0, 3.0, 4.0, 4.0, 4.0, 3.0, 4.0, 4.0, 5.0, 4.0, 5.0, 4.0, 5.0, 5.0, 3.0, 5.0, 5.0, 4.0, 4.0, 5.0, 4.0, 4.0, 4.0, 4.0, 5.0, 3.0, 4.0, 5.0, 4.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 1.0, 5.0, 4.0, 4.0, 4.0, 5.0, 4.0, 3.0, 5.0, 4.0, 3.0, 3.0, 5.0, 2.0, 5.0, 3.0, 5.0, 5.0, 5.0, 3.0, 3.0, 5.0, 4.0, 4.0, 5.0, 2.0, 4.0, 3.0, 4.0, 5.0, 4.0, 4.0, 4.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 5.0, 4.0, 5.0, 5.0, 3.0, 4.0, 5.0, 4.0, 2.0, 5.0, 4.0, 5.0, 5.0, 5.0, 1.0, 3.0, 4.0, 3.0, 5.0, 5.0, 5.0, 2.0, 4.0, 1.0, 2.0, 5.0, 4.0, 5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 5.0, 2.0, 4.0, 4.0, 3.0, 4.0, 5.0, 5.0, 4.0, 4.0, 4.0, 2.0, 4.0, 4.0, 2.0, 4.0, 1.0, 5.0, 3.0, 5.0, 4.0, 5.0, 4.0, 2.0, 5.0, 4.0, 4.0, 5.0, 4.0, 5.0, 3.0, 5.0, 5.0, 3.0, 3.0, 4.0, 3.0, 4.0, 3.0, 2.0, 4.0, 4.0, 5.0, 4.0, 3.0, 5.0, 5.0, 3.0, 3.0, 3.0, 4.0, 5.0, 5.0, 4.0, 4.0, 3.0, 4.0, 5.0, 4.0, 5.0, 3.0, 5.0, 4.0, 5.0, 4.0, 3.0, 5.0, 3.0, 3.0, 2.0, 4.0, 5.0, 4.0, 4.0, 3.0, 5.0, 4.0, 5.0, 4.0, 2.0, 5.0, 4.0, 3.0, 5.0, 3.0, 5.0, 1.0, 5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 5.0, 4.0, 4.0, 5.0, 5.0, 5.0, 4.0, 4.0, 3.0, 5.0, 5.0, 4.0, 5.0, 4.0, 5.0, 4.0, 5.0, 5.0, 5.0, 5.0, 3.0, 4.0, 5.0, 3.0, 4.0, 4.0, 5.0, 3.0, 5.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 4.0, 5.0, 3.0, 2.0, 4.0, 4.0, 5.0, 2.0, 3.0, 5.0, 4.0, 5.0, 3.0, 4.0, 5.0, 5.0, 3.0, 2.0, 4.0, 5.0, 1.0, 4.0, 4.0, 5.0, 4.0, 1.0, 4.0, 5.0, 4.0, 5.0, 4.0, 5.0, 5.0, 5.0, 5.0, 4.0, 3.0, 4.0, 4.0, 5.0, 3.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 5.0, 5.0, 4.0, 5.0, 2.0, 2.0, 4.0, 4.0, 5.0, 4.0, 5.0, 3.0, 5.0, 5.0, 4.0, 4.0, 3.0, 1.0, 3.0, 3.0, 1.0, 5.0, 4.0, 4.0, 4.0, 5.0, 3.0, 5.0, 4.0, 5.0, 4.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 5.0, 4.0, 4.0, 5.0, 3.0, 3.0, 5.0, 4.0, 5.0, 4.0, 4.0, 1.0, 3.0, 4.0, 4.0, 4.0, 5.0, 5.0, 2.0, 1.0, 3.0, 3.0, 4.0, 3.0, 3.0, 2.0, 5.0, 5.0, "
     ]
    }
   ],
   "source": [
    "for i in random_users_id_list:\n",
    "    print(np.sum(test_matrix[i]), end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, "
     ]
    }
   ],
   "source": [
    "for i in range(94):\n",
    "    print(train_matrix[random_users_id_list[i]][users_first_rating_movie[i]], end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (6040, 6040)\n",
      "type:  <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.09638153, 0.12060981, ..., 0.        , 0.17460369,\n",
       "        0.13359025],\n",
       "       [0.09638153, 1.        , 0.1514786 , ..., 0.06611767, 0.0664575 ,\n",
       "        0.21827563],\n",
       "       [0.12060981, 0.1514786 , 1.        , ..., 0.12023352, 0.09467506,\n",
       "        0.13314404],\n",
       "       ...,\n",
       "       [0.        , 0.06611767, 0.12023352, ..., 1.        , 0.16171426,\n",
       "        0.09930008],\n",
       "       [0.17460369, 0.0664575 , 0.09467506, ..., 0.16171426, 1.        ,\n",
       "        0.22833237],\n",
       "       [0.13359025, 0.21827563, 0.13314404, ..., 0.09930008, 0.22833237,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-user_similart\n",
    "user_similarity = pairwise_distances(train_matrix, metric='cosine')\n",
    "user_similarity=1-user_similarity\n",
    "print('shape: ',user_similarity.shape)\n",
    "print('type: ',type(user_similarity))\n",
    "user_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(user_similarity)):\n",
    "    for j in range(len(user_similarity)):\n",
    "        if i == j:\n",
    "            user_similarity[i][j]=0\n",
    "        else:\n",
    "            continue\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,0.0 ,"
     ]
    }
   ],
   "source": [
    "for i in range(len(user_similarity)):\n",
    "    print(user_similarity[i][i], end=\" ,\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_user_user(train_matrix, user_similarity, n_similar=30):\n",
    "    # sort edip ters indexlerini ters çeviriyor seçilen en yakın user sayısına göre\n",
    "    similar_n = user_similarity.argsort()[:,n_similar:][:,::-1]# kontrol et\n",
    "    # pred matrix'i oluşturuluyor\n",
    "    pred = np.zeros((n_users_base,n_items_base))\n",
    "    \n",
    "    for i,users in enumerate(similar_n):# pred yapılıyor\n",
    "        similar_users_indexes = users\n",
    "        similarity_n = user_similarity[i,similar_users_indexes]\n",
    "        matrix_n = train_matrix[similar_users_indexes,:]\n",
    "        rated_items = similarity_n[:,np.newaxis].T.dot(matrix_n - matrix_n.mean(axis=1)[:,np.newaxis])/ similarity_n.sum()\n",
    "        pred[i,:]  = rated_items\n",
    "        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions shape  (6040, 3952)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.72618284,  0.3669082 ,  0.15464969, ..., -0.08897578,\n",
       "        -0.10445441,  0.14311739],\n",
       "       [ 1.5198873 ,  0.41302634,  0.22270161, ..., -0.03125381,\n",
       "        -0.05083353,  0.22091092],\n",
       "       [ 1.50890854,  0.35922931,  0.15123694, ..., -0.09588757,\n",
       "        -0.11519368,  0.11498493],\n",
       "       ...,\n",
       "       [ 1.54341024,  0.27647603,  0.10202431, ..., -0.13030558,\n",
       "        -0.15099003,  0.09597635],\n",
       "       [ 1.58269725,  0.3868667 ,  0.18575528, ..., -0.03644404,\n",
       "        -0.05606499,  0.18425771],\n",
       "       [ 1.70370085,  0.53045888,  0.35494243, ...,  0.1553014 ,\n",
       "         0.13638447,  0.41736532]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predict_user_user(train_matrix,user_similarity, 30) + train_matrix.mean(axis=1)[:, np.newaxis]# 30 olması daha iyi\n",
    "print('predictions shape ',predictions.shape)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings = predictions[test_matrix.nonzero()]\n",
    "\n",
    "test_truth = test_matrix[test_matrix.nonzero()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.958535700276364"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.sqrt(mean_squared_error(predicted_ratings,test_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4., 5., 4., 4., 4., 2., 5., 1., 3., 4., 5., 5., 5., 2., 5., 3., 3.,\n",
       "       5., 4., 5., 5., 3., 3., 3., 4., 2., 3., 5., 4., 4., 1., 5., 5., 3.,\n",
       "       4., 3., 4., 2., 4., 5., 4., 5., 4., 2., 4., 5., 4., 5., 5., 3., 3.,\n",
       "       4., 5., 5., 3., 5., 5., 4., 5., 4., 5., 3., 5., 4., 4., 4., 3., 5.,\n",
       "       3., 5., 5., 5., 3., 4., 4., 2., 5., 3., 5., 4., 3., 4., 5., 4., 4.,\n",
       "       4., 3., 4., 3., 5., 4., 3., 5., 4., 3., 4., 2., 2., 3., 5., 5., 3.,\n",
       "       4., 4., 4., 5., 5., 4., 2., 3., 5., 5., 3., 5., 4., 4., 4., 3., 3.,\n",
       "       4., 4., 2., 3., 4., 3., 2., 2., 3., 4., 4., 4., 4., 5., 3., 5., 5.,\n",
       "       5., 2., 4., 4., 3., 4., 5., 4., 5., 4., 4., 4., 1., 4., 5., 4., 2.,\n",
       "       4., 2., 5., 4., 4., 4., 3., 5., 4., 3., 4., 4., 4., 4., 3., 4., 5.,\n",
       "       5., 5., 5., 2., 2., 5., 4., 5., 5., 2., 3., 4., 3., 4., 3., 5., 5.,\n",
       "       4., 5., 3., 5., 4., 4., 5., 2., 4., 4., 3., 5., 4., 3., 4., 4., 4.,\n",
       "       5., 2., 4., 4., 1., 3., 4., 4., 5., 3., 4., 5., 5., 4., 5., 4., 4.,\n",
       "       4., 4., 2., 4., 5., 3., 3., 4., 4., 4., 3., 4., 4., 4., 4., 5., 5.,\n",
       "       1., 4., 2., 5., 1., 4., 5., 4., 4., 3., 5., 2., 4., 5., 3., 3., 3.,\n",
       "       4., 4., 5., 3., 4., 4., 4., 3., 4., 4., 5., 4., 5., 4., 5., 5., 3.,\n",
       "       5., 5., 4., 4., 5., 4., 4., 4., 4., 5., 3., 4., 5., 4., 5., 5., 5.,\n",
       "       4., 4., 4., 1., 5., 4., 4., 4., 5., 4., 3., 5., 4., 3., 3., 5., 2.,\n",
       "       5., 3., 5., 5., 5., 3., 3., 5., 4., 4., 5., 2., 4., 3., 4., 5., 4.,\n",
       "       4., 4., 3., 5., 5., 4., 3., 3., 5., 4., 5., 5., 3., 4., 5., 4., 2.,\n",
       "       5., 4., 5., 5., 5., 1., 3., 4., 3., 5., 5., 5., 2., 4., 1., 2., 5.,\n",
       "       4., 5., 5., 5., 4., 5., 5., 5., 2., 4., 4., 3., 4., 5., 5., 4., 4.,\n",
       "       4., 2., 4., 4., 2., 4., 1., 5., 3., 5., 4., 5., 4., 2., 5., 4., 4.,\n",
       "       5., 4., 5., 3., 5., 5., 3., 3., 4., 3., 4., 3., 2., 4., 4., 5., 4.,\n",
       "       3., 5., 5., 3., 3., 3., 4., 5., 5., 4., 4., 3., 4., 5., 4., 5., 3.,\n",
       "       5., 4., 5., 4., 3., 5., 3., 3., 2., 4., 5., 4., 4., 3., 5., 4., 5.,\n",
       "       4., 2., 5., 4., 3., 5., 3., 5., 1., 5., 5., 5., 4., 5., 5., 5., 4.,\n",
       "       4., 5., 5., 5., 4., 4., 3., 5., 5., 4., 5., 4., 5., 4., 5., 5., 5.,\n",
       "       5., 3., 4., 5., 3., 4., 4., 5., 3., 5., 3., 4., 4., 3., 3., 3., 4.,\n",
       "       5., 3., 2., 4., 4., 5., 2., 3., 5., 4., 5., 3., 4., 5., 5., 3., 2.,\n",
       "       4., 5., 1., 4., 4., 5., 4., 1., 4., 5., 4., 5., 4., 5., 5., 5., 5.,\n",
       "       4., 3., 4., 4., 5., 3., 3., 4., 2., 3., 2., 3., 5., 5., 4., 5., 2.,\n",
       "       2., 4., 4., 5., 4., 5., 3., 5., 5., 4., 4., 3., 1., 3., 3., 1., 5.,\n",
       "       4., 4., 4., 5., 3., 5., 4., 5., 4., 3., 4., 3., 4., 4., 4., 5., 4.,\n",
       "       4., 5., 3., 3., 5., 4., 5., 4., 4., 1., 3., 4., 4., 4., 5., 5., 2.,\n",
       "       1., 3., 3., 4., 3., 3., 2., 5., 5.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.07832142e-01,  1.55984157e+00,  1.67911823e+00,  8.64904136e-01,\n",
       "        8.56453631e-01,  1.22303586e+00,  1.98428879e+00,  9.42631951e-01,\n",
       "        1.30050531e+00,  1.55574557e+00,  1.45990769e+00,  1.27265884e+00,\n",
       "        1.79660457e+00,  1.80785207e+00,  3.07188132e-01,  1.62109238e+00,\n",
       "        2.02031042e+00,  1.64346080e+00,  1.53072034e+00,  7.52205333e-01,\n",
       "        1.58024114e+00, -4.58557922e-02,  4.62507718e-01, -1.06156208e-01,\n",
       "        1.92155991e+00,  8.84685402e-01,  4.75727157e-01,  1.67578244e+00,\n",
       "        1.68522790e+00,  2.11181767e+00,  1.37590190e+00,  1.84416141e+00,\n",
       "        2.50086549e-01,  1.03318900e+00,  1.26216280e+00,  5.55337724e-01,\n",
       "        1.72398571e+00,  1.57674552e+00,  9.00117766e-01,  2.52583552e+00,\n",
       "        1.26543215e+00,  1.56441430e+00,  1.11635203e+00,  2.78013359e-01,\n",
       "        7.36858332e-01,  2.18477565e+00,  8.88843323e-02,  1.76647723e+00,\n",
       "        1.58655445e+00,  9.76859181e-01,  6.30903858e-01,  1.58995597e+00,\n",
       "        2.08501291e+00,  8.04783211e-01,  6.67852173e-01,  1.04059326e+00,\n",
       "        9.16664996e-01,  6.99327751e-03,  2.05998794e+00,  5.64369288e-01,\n",
       "        1.61977281e+00,  1.75476310e+00,  7.32567350e-01,  2.09610818e+00,\n",
       "        8.42184898e-01,  6.07663613e-02,  8.13519985e-01,  2.25645322e+00,\n",
       "        4.46056059e-01,  7.05312340e-01,  2.15696767e+00,  1.79055605e+00,\n",
       "        1.88056038e+00,  1.09115560e+00,  7.95913799e-01,  4.26314080e-01,\n",
       "        2.79440740e+00,  1.65564442e+00,  1.06709781e+00,  1.65032249e+00,\n",
       "        7.42491793e-02,  8.34305081e-01,  1.15372000e+00,  1.81235320e+00,\n",
       "        8.46638088e-01,  9.75759790e-01,  3.43166162e-01,  1.56925571e+00,\n",
       "        1.93523889e+00,  7.35625822e-01,  1.03828237e+00,  1.66425959e+00,\n",
       "        9.22756102e-01,  6.82496847e-01,  1.69089304e-01,  1.50965521e-01,\n",
       "        2.67707933e-01,  6.82968817e-01,  1.55064909e+00,  7.80810665e-01,\n",
       "        1.74328109e+00,  1.17681424e+00,  4.14602277e-01,  1.63999754e+00,\n",
       "        1.74910098e+00,  2.21811826e+00,  1.83954251e+00,  3.45554742e-01,\n",
       "       -1.73225368e-01,  2.28569889e-01,  1.76749780e+00,  2.52655892e+00,\n",
       "        2.54190009e+00,  1.54502361e+00,  1.78319843e+00,  1.07164212e+00,\n",
       "        2.85389840e-01,  3.93974963e-01,  4.21547399e-01,  1.87244409e+00,\n",
       "       -6.23009372e-02,  9.52495613e-01,  1.74379632e+00,  1.69346367e+00,\n",
       "        2.92754082e-01,  7.99714845e-02,  1.49565390e+00, -6.76638914e-02,\n",
       "        6.33302864e-02,  8.42546471e-01,  1.77352731e+00,  1.75436680e+00,\n",
       "        2.13716437e+00,  1.12266409e-01,  1.19405400e+00,  1.65320978e+00,\n",
       "        1.84639223e+00,  2.65252385e-01,  7.13965965e-01,  1.60549666e+00,\n",
       "        1.81539197e+00,  1.21711661e+00,  3.13972499e-01,  7.07612654e-01,\n",
       "        1.39370529e+00,  1.24449062e+00,  1.19240650e+00,  2.97590829e-01,\n",
       "        2.96492266e-01,  9.65496036e-01,  1.66426320e+00,  2.07956815e+00,\n",
       "        1.74357909e+00,  6.18094952e-02,  1.83038983e-01,  6.86119977e-01,\n",
       "        1.76579348e+00,  1.75980893e+00,  7.39852966e-01,  5.48701896e-01,\n",
       "        1.63886908e+00,  2.94579366e-01,  2.36474850e-01,  8.23914305e-01,\n",
       "        4.83508526e-01,  1.18975066e+00,  1.80277678e+00,  2.52567603e-01,\n",
       "        1.46985493e+00,  1.60026344e+00,  1.10270328e+00,  3.54907775e-01,\n",
       "        6.89994440e-01,  9.98857330e-02,  1.30996047e+00,  2.19899235e+00,\n",
       "        8.22685836e-01,  1.93976585e+00,  1.85825995e+00,  2.02281635e+00,\n",
       "        1.56773016e+00, -1.18284116e-01,  2.97185450e-01,  1.83973857e+00,\n",
       "        1.90725519e+00,  1.64867869e+00,  1.74631605e+00,  8.37353950e-01,\n",
       "        1.53477069e+00,  5.36035566e-01,  1.61276091e+00,  1.46130441e+00,\n",
       "        1.61484748e+00,  1.48101296e+00, -1.99519406e-03, -1.78412224e-02,\n",
       "        1.61315248e+00,  6.39033423e-01,  1.40615859e+00,  2.13904263e+00,\n",
       "        9.69481530e-01,  1.29238394e+00,  2.02636632e+00,  1.01633066e+00,\n",
       "        1.80165824e+00,  4.82683683e-01,  6.27945780e-01,  1.71017091e+00,\n",
       "        3.43202524e-01,  1.98516996e-01,  1.34754689e+00,  1.66925574e+00,\n",
       "        1.59631989e+00, -8.15541922e-02,  1.84532604e+00,  1.48463132e+00,\n",
       "        7.39980941e-01,  7.91181711e-01,  2.22117838e-01,  1.36981556e+00,\n",
       "        3.55410093e-01,  1.40049335e+00,  6.50051415e-02,  2.07010936e-01,\n",
       "        3.04874827e-01,  1.84806030e+00,  5.57267893e-01,  1.81077136e+00,\n",
       "        1.43137592e-01,  2.42769403e-01,  1.14245941e+00,  7.25070521e-01,\n",
       "        1.99592390e+00,  1.03756469e+00,  1.61741818e+00,  1.56105619e+00,\n",
       "       -1.17304023e-01,  6.04617811e-01,  1.20284671e+00,  2.67657047e+00,\n",
       "        1.31509631e+00,  1.07904160e+00,  4.07579656e-01,  1.05265718e+00,\n",
       "        4.17700846e-01,  1.71201931e+00,  1.88932316e+00,  1.52469953e+00,\n",
       "        2.99171571e-01,  3.55332949e-01, -2.63776365e-03,  1.91512432e+00,\n",
       "        3.96810628e-01,  1.21641190e+00,  2.06250906e+00,  1.59310006e+00,\n",
       "        1.39856702e+00,  1.61206163e+00,  9.77697757e-01,  7.66976499e-01,\n",
       "        1.05048274e+00,  2.27853266e-01,  4.34562541e-01,  1.56157671e+00,\n",
       "        2.76233283e-01,  1.72735039e+00,  1.82270742e+00,  4.99233074e-01,\n",
       "        1.51038217e+00,  1.33478078e+00,  6.62737030e-01,  1.75079073e+00,\n",
       "        1.73093349e+00,  1.36867618e+00,  6.56099611e-01,  1.16361512e+00,\n",
       "        1.60976812e+00,  1.11386462e+00,  1.04024530e+00,  2.14465639e+00,\n",
       "        1.67528669e+00,  1.80893572e+00,  1.04451348e+00,  9.53853313e-01,\n",
       "        6.82984290e-01,  6.66035452e-01,  1.54933719e+00,  1.80740983e+00,\n",
       "        6.69354527e-01,  1.17787273e+00,  1.02418319e+00,  1.66041912e+00,\n",
       "       -3.95968951e-02,  1.37381756e+00,  6.23680387e-01,  1.60564351e+00,\n",
       "        7.69469599e-01,  5.90309534e-01,  8.34647901e-01,  3.29181488e-01,\n",
       "        7.74982443e-01,  6.58207911e-01, -6.58744698e-02,  6.36437894e-01,\n",
       "        1.24643676e+00,  1.96960463e+00,  2.33023723e-01,  1.49322893e+00,\n",
       "        1.05626334e+00,  3.39790893e-01,  7.14834565e-01,  4.51596752e-01,\n",
       "        4.00292980e-01,  1.95157239e+00,  1.79820864e+00,  2.41652668e+00,\n",
       "        8.37668534e-01,  7.83028695e-01,  9.31863788e-01,  3.56996686e-01,\n",
       "        5.99277603e-01,  1.84177685e+00,  1.41733416e+00,  1.87048920e+00,\n",
       "        1.58367691e+00,  4.37586704e-01,  1.50063571e+00,  2.03558327e+00,\n",
       "        7.90668892e-01,  1.64658598e+00,  1.02658385e+00,  1.57796208e+00,\n",
       "        9.58150990e-01,  2.23445090e+00,  1.74439311e+00,  9.96937242e-01,\n",
       "        1.61352399e+00,  1.92939826e+00,  1.73750764e+00,  3.06790853e-01,\n",
       "        1.87765221e+00,  2.52311007e+00,  1.72307091e+00,  1.62517259e+00,\n",
       "        1.52703216e+00,  1.42945162e+00,  6.01126934e-01,  1.45747481e+00,\n",
       "        4.75160642e-01,  2.18166746e+00,  1.26289185e+00,  8.16516827e-01,\n",
       "        3.81566048e-01,  8.05790597e-01, -8.08911247e-02,  1.07374603e+00,\n",
       "        2.03989981e+00,  8.21718044e-02,  6.61528759e-01,  4.72732100e-01,\n",
       "        7.72909109e-01,  1.41218443e+00,  1.63198318e+00,  1.85159139e+00,\n",
       "        1.73701285e+00,  3.73402275e-01,  1.94862483e+00,  8.30763845e-01,\n",
       "        2.49398636e-01,  2.17804694e+00,  1.76258951e+00,  1.66882991e+00,\n",
       "        1.94213309e+00,  1.26183401e+00,  1.67843907e-01,  1.13102369e-01,\n",
       "        1.10634849e+00,  2.09088507e+00,  4.03325539e-01,  7.87585140e-01,\n",
       "       -5.40974098e-02,  1.73289591e+00,  2.56782818e-02,  2.92776550e-01,\n",
       "        2.01927470e-01,  2.98329840e+00,  2.01353970e+00,  1.33473360e+00,\n",
       "        1.74475382e+00,  1.69614789e+00,  1.31391391e+00,  1.76322403e+00,\n",
       "        5.50059383e-01,  2.60790266e+00,  1.36255967e+00,  8.43517561e-01,\n",
       "        1.60372417e+00,  5.62791784e-01,  1.77769472e+00,  1.72180908e+00,\n",
       "        3.90044550e-01,  1.54875299e+00,  3.84736966e-01,  5.68518275e-02,\n",
       "        1.08405456e+00,  1.79624180e+00,  1.58072963e+00,  2.66628704e-01,\n",
       "        1.04906451e-01,  6.51117380e-01,  1.42795696e+00,  1.53833047e-02,\n",
       "        1.20109176e+00,  4.05698615e-01,  1.57981178e+00,  1.77777627e+00,\n",
       "        1.69939462e+00,  1.80236554e-01,  1.65679398e+00,  1.65683081e+00,\n",
       "        1.86799245e+00,  9.04440292e-01,  8.58317936e-01,  8.90106641e-01,\n",
       "        1.62911477e+00,  7.43427919e-01,  1.80128357e+00,  1.85810603e+00,\n",
       "        8.90505451e-01,  9.26806597e-01,  2.77029454e+00,  9.54012004e-01,\n",
       "       -5.80133133e-02,  7.68333386e-01,  1.07819013e+00,  1.58520920e+00,\n",
       "        2.80535052e+00,  1.75240639e+00,  7.61318646e-02,  1.54945495e+00,\n",
       "        1.10370866e+00,  1.77230201e+00, -6.09732308e-02,  1.76047325e-01,\n",
       "        1.99608831e+00,  8.52031176e-01,  3.43731802e-01,  1.68814533e+00,\n",
       "        1.48523639e+00,  1.57882210e+00,  2.21468487e+00, -8.44713630e-02,\n",
       "        8.24059512e-01,  5.51764445e-01,  7.39444498e-01,  5.41666961e-02,\n",
       "        1.54211506e+00,  2.89190306e-01,  1.22459879e+00,  8.87643246e-02,\n",
       "        1.88945547e+00,  1.78467688e+00,  2.00530998e+00, -8.11008368e-02,\n",
       "        1.75591610e+00,  6.43992344e-01,  1.52759392e+00,  6.95192334e-01,\n",
       "        9.35679605e-01,  1.67213193e+00,  1.54316911e+00,  1.15590599e+00,\n",
       "        1.39022611e+00,  1.72326559e+00,  1.48557575e+00,  1.72588477e+00,\n",
       "        1.88922936e+00,  6.11271710e-01,  7.39714891e-01,  1.51659737e+00,\n",
       "        2.51023526e-01,  1.67676195e+00,  1.89209777e+00,  1.38665872e+00,\n",
       "        4.30647892e-01,  1.49623413e+00,  1.42483093e+00,  4.56615370e-02,\n",
       "        7.38387692e-01,  1.62331854e+00,  1.50760997e+00,  1.10854492e-01,\n",
       "        1.75432364e-01,  2.90980856e+00, -7.22623606e-02,  1.60840907e+00,\n",
       "        5.30816974e-01,  2.07260592e-01,  1.58387585e+00,  1.77147946e+00,\n",
       "        1.83874531e+00,  1.87474606e+00,  5.76845364e-01,  2.59472363e+00,\n",
       "        1.53448328e+00,  1.59005018e+00,  8.94923762e-01,  2.08111305e+00,\n",
       "        4.78888698e-01,  1.10273918e+00,  7.30906771e-01,  1.77333675e+00,\n",
       "        9.93448678e-03,  2.99194854e+00,  7.82019746e-01,  1.57048340e+00,\n",
       "        8.25930159e-01,  1.36793977e+00,  1.49753039e+00,  2.20271523e+00,\n",
       "        1.44907642e+00,  1.94630490e+00,  2.19395947e-01,  1.93457734e+00,\n",
       "        1.42168967e+00,  1.46191823e+00,  1.53544708e+00,  7.29601031e-01,\n",
       "        1.98392512e+00,  1.56107902e+00,  7.81153255e-01,  1.85187610e+00,\n",
       "        1.57947563e+00,  2.89592916e-02,  8.12494950e-02,  1.60268988e+00,\n",
       "        1.54232527e+00,  2.64556676e-01,  2.93365978e-01,  1.44415605e+00,\n",
       "        2.82902133e-01,  8.88237232e-01,  8.83381335e-01,  7.53385876e-01,\n",
       "        1.47921302e+00,  7.07145018e-01,  8.60708853e-01,  2.98825036e-01,\n",
       "        1.61848277e+00,  1.87359377e+00,  1.51745245e+00,  2.14007336e+00,\n",
       "        1.35457229e+00,  1.59361176e+00,  1.76035555e+00,  9.20478715e-01,\n",
       "        7.23606482e-01,  9.61102171e-01, -1.01434177e-01,  5.08543175e-02,\n",
       "        1.47727055e+00,  1.93801815e+00,  7.61731198e-01,  1.44087209e+00,\n",
       "       -1.64987854e-02,  1.76425570e+00,  1.46254888e+00,  1.05028002e+00,\n",
       "       -9.96322749e-03,  1.75477691e+00,  1.09881624e+00,  1.12916027e+00,\n",
       "        1.42996833e+00,  1.57826129e-03,  5.90720952e-01,  4.63321208e-01,\n",
       "        1.67661469e+00,  1.99681309e+00,  8.27558425e-01,  6.05863051e-01,\n",
       "        1.74846190e+00,  9.55264617e-01,  1.45347181e+00,  4.30139669e-01,\n",
       "        3.14707503e-01,  6.69989639e-01,  1.64500209e+00,  1.06445812e-01,\n",
       "        7.47743271e-01,  1.36356713e+00,  8.54748487e-01,  3.84430485e-01,\n",
       "        1.10166638e+00,  9.72828670e-01,  7.08726036e-02,  3.87272173e-01,\n",
       "        9.38148353e-01,  1.67483207e+00,  6.89641950e-01,  6.01403644e-01,\n",
       "        4.86747637e-01,  9.17528933e-01,  9.90271152e-01, -1.04263983e-01])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8078321419084351"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5598415736942717"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6791182283957222"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_truth[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_truth[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
